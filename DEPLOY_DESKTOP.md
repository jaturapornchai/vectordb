# Vector Search API - Desktop Deployment Guide

## üì¶ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°

1. **Docker Desktop** (Windows/Mac/Linux)
   - Download: https://www.docker.com/products/docker-desktop
   - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏¥‡∏î Docker Desktop ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

2. **‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ**
   - `docker-compose.yml`
   - `Dockerfile`
   - `.env` (API keys)
   - `doc/` folder (‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤)
   - Source code (*.go files)

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ Deploy ‡∏ö‡∏ô Desktop

### 1. Clone ‡∏´‡∏£‡∏∑‡∏≠ Copy ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ

```powershell
# ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ git
git clone <repository-url>
cd vectordb

# ‡∏´‡∏£‡∏∑‡∏≠ copy folder ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡∏ó‡∏µ‡πà Desktop
```

### 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° .env File

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `.env` ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå vectordb:

```env
# AI API Configuration
GEMINI_API_KEY=your_gemini_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Ollama Configuration
OLLAMA_HOST=http://ollama:11434
OLLAMA_MODEL=llama3.2

# Database (‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö text search)
DB_HOST=localhost
DB_PORT=5432
```

### 3. Pull Ollama Model ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å

**Windows (PowerShell):**
```powershell
# Start services
docker-compose up -d

# ‡∏£‡∏≠ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÉ‡∏´‡πâ Ollama ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
Start-Sleep -Seconds 10

# Pull model
docker exec ollama ollama pull llama3.2:latest

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
docker exec ollama ollama list
```

**Mac/Linux (Terminal):**
```bash
# Start services
docker-compose up -d

# ‡∏£‡∏≠ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
sleep 10

# Pull model
docker exec ollama ollama pull llama3.2:latest

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
docker exec ollama ollama list
```

### 4. Start Services

```powershell
# Windows
docker-compose up -d

# Mac/Linux
docker-compose up -d
```

### 5. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞

```powershell
# ‡∏î‡∏π logs
docker-compose logs -f vectordb-api

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ service ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
docker ps

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö health check
curl http://localhost:8080/health
```

## üìù ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏£‡∏∏‡∏õ)

**Windows PowerShell:**
```powershell
$body = @{
    query = "‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á"
    useSummary = $false
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:8080/search" `
    -Method Post `
    -Body $body `
    -ContentType "application/json; charset=utf-8"
```

**Mac/Linux (curl):**
```bash
curl -X POST http://localhost:8080/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á",
    "useSummary": false
  }'
```

### ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ + ‡∏™‡∏£‡∏∏‡∏õ‡∏î‡πâ‡∏ß‡∏¢ AI

**Windows PowerShell:**
```powershell
$body = @{
    query = "‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á"
    useSummary = $true
} | ConvertTo-Json

$response = Invoke-RestMethod -Uri "http://localhost:8080/search" `
    -Method Post `
    -Body $body `
    -ContentType "application/json; charset=utf-8"

Write-Host "`n=== ‡∏™‡∏£‡∏∏‡∏õ ===" -ForegroundColor Cyan
Write-Host $response.summary -ForegroundColor Green
Write-Host "`n=== ‡∏û‡∏ö $($response.total) ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ===" -ForegroundColor Yellow
```

**Mac/Linux (curl + jq):**
```bash
curl -X POST http://localhost:8080/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á",
    "useSummary": true
  }' | jq '.summary'
```

## üõ†Ô∏è ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Services

### Stop Services
```powershell
docker-compose stop
```

### Restart Services
```powershell
docker-compose restart
```

### ‡∏•‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏£‡∏ß‡∏° volumes)
```powershell
docker-compose down -v
```

### Rebuild ‡πÉ‡∏´‡∏°‡πà‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Å‡πâ code
```powershell
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

## üìÇ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà

1. ‡∏ß‡∏≤‡∏á markdown files ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `doc/`
2. Restart service:
   ```powershell
   docker-compose restart vectordb-api
   ```
3. ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

## üîç ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
```powershell
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ "‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á"
$body = @{ query = "‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á"; useSummary = $false } | ConvertTo-Json
Invoke-RestMethod -Uri "http://localhost:8080/search" -Method Post -Body $body -ContentType "application/json; charset=utf-8"
```

### 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡∏à‡∏∞‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ó‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
```powershell
# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ "tile" ‚Üí Ollama ‡∏à‡∏∞‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô "‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á"
$body = @{ query = "tile"; useSummary = $false } | ConvertTo-Json
Invoke-RestMethod -Uri "http://localhost:8080/search" -Method Post -Body $body -ContentType "application/json; charset=utf-8"
```

### 3. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ + ‡∏™‡∏£‡∏∏‡∏õ
```powershell
$body = @{ query = "‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô"; useSummary = $true } | ConvertTo-Json
$result = Invoke-RestMethod -Uri "http://localhost:8080/search" -Method Post -Body $body -ContentType "application/json; charset=utf-8"
$result.summary
```

## ‚ùì Troubleshooting

### Port 8080 ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß
‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô `docker-compose.yml`:
```yaml
ports:
  - "8081:8080"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô port ‡∏≠‡∏∑‡πà‡∏ô
```

### Ollama ‡πÉ‡∏ä‡πâ RAM ‡πÄ‡∏¢‡∏≠‡∏∞
‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô `docker-compose.yml`:
```yaml
ollama:
  deploy:
    resources:
      limits:
        memory: 2G  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î RAM
```

### ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
```powershell
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô container
docker exec vectordb-api ls -la /app/doc/

# ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ rebuild
docker-compose down
docker-compose build
docker-compose up -d
```

### Ollama ‡∏ä‡πâ‡∏≤
```powershell
# ‡πÉ‡∏ä‡πâ model ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤
docker exec ollama ollama pull llama3.2:1b

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô queryexpansion.go
Model: "llama3.2:1b"
```

## üìä Performance

- **RAM**: ‚â• 8GB ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
- **Disk**: ‚â• 5GB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ollama models
- **CPU**: ‚â• 4 cores ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥

**Ollama Models:**
- `llama3.2:1b` - ‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î, ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (1.3GB)
- `llama3.2:3b` - ‡∏Å‡∏•‡∏≤‡∏á (2GB)
- `llama3.2:latest` - ‡πÉ‡∏´‡∏ç‡πà, ‡πÅ‡∏°‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (2GB)

## üîê Security

1. **‡∏≠‡∏¢‡πà‡∏≤ commit `.env` file** (‡πÉ‡∏™‡πà‡πÉ‡∏ô `.gitignore`)
2. **API Keys**: ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô `.env` ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. **Production**: ‡πÉ‡∏ä‡πâ reverse proxy (nginx) + SSL

## üì± Integration

### Python
```python
import requests

response = requests.post(
    "http://localhost:8080/search",
    json={"query": "‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á", "useSummary": True}
)
print(response.json()["summary"])
```

### Node.js
```javascript
const axios = require('axios');

axios.post('http://localhost:8080/search', {
  query: '‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á',
  useSummary: true
}).then(res => {
  console.log(res.data.summary);
});
```

### cURL
```bash
curl -X POST http://localhost:8080/search \
  -H "Content-Type: application/json" \
  -d '{"query":"‡∏Å‡∏£‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á","useSummary":true}'
```

## üéØ Features

‚úÖ **‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ AI**: ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡∏Ñ‡∏≥‡∏û‡πâ‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á, ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤)
‚úÖ **Multi-language**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
‚úÖ **Smart Summary**: ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ Gemini/DeepSeek API
‚úÖ **Fast**: Text search ‡πÅ‡∏ö‡∏ö realtime
‚úÖ **No Database**: ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PostgreSQL
‚úÖ **Portable**: ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ö‡∏ô Windows/Mac/Linux

## üìû Support

- GitHub Issues: [repository-url]/issues
- Email: your-email@example.com
